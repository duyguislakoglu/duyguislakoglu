<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Sebastijan Dumančić | <strong>Deep learning for <br/>  complex relational data</strong></title>
  <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

  <link rel="shortcut icon" href="/assets/img/favicon.ico">

  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="canonical" href="/phd_defence/">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    
    <span class="site-title">
        
        <strong>Sebastijan</strong> Dumančić
    </span>
    

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

      <div class="trigger">
        <!-- About -->
        <a class="page-link" href="/">about</a>

        <!-- Blog -->
        <!-- <a class="page-link" href="/blog/">blog</a> -->

        <!-- Pages -->
        
          
            
          
        
          
            
          
        
          
            
          
        
          
        
          
            
            	<a class="page-link" href="/publications/">publications</a>
	    
          
        
          
            
            	<a class="page-link" href="/teaching/">teaching</a>
	    
          
        
          
            
            	<a class="page-link" href="/varia/">varia</a>
	    
          
        
          
            
          
        
          
            
          
        

        <!-- CV link -->
        <!-- <a class="page-link" href="/assets/pdf/CV.pdf">vitae</a> -->

      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title"><strong>Deep learning for <br/>  complex relational data</strong></h1>
    <h5 class="post-description">Symposium on the occasion of the public PhD defence of Sebastijan Dumančić</h5>
  </header>

  <article class="post-content <strong>Deep learning for <br/>  complex relational data</strong> clearfix">
    <div class="profile col defence-picture right">
    
      <img class="defence-picture" src="/assets/img/defence/arenbergwide.jpg">
    
 </div>

<p align="justify">
I cordially invite you to my public PhD defence, the preceding symposium and the subsequent reception on <strong>Tuesday, December 11, 2018</strong>.
The defence will take place in the <strong>Auditorium</strong> (KAST 01.07) <strong>of the Arenberg castle</strong> (<a href="https://www.google.be/maps/place/Kasteelpark+Arenberg+1,+3001+Leuven/data=!4m2!3m1!1s0x47c16116b88ff81f:0xc63a120b549ee9c5?ved=2ahUKEwjkzoesgejeAhVQx4UKHdRfADQQ8gEwAHoECAAQAQ">Kasteelpark Arenberg 1, 3001 Heverlee</a>) starting at <strong>17:00</strong>; the reception will take place in the Prinsenzaal of the Castle.
</p>

<p align="justify">
The defence is preceded by a symposium on "Deep learning for complex relational data" featuring the talks of <a href="http://www.riedelcastro.org/">Sebastian Riedel</a> (University College London, UK), <a href="http://www.matlog.net/">Mathias Niepert</a> (NEC Labs Heidelberg, Germany) and <a href="http://web.cs.ucla.edu/~guyvdb/">Guy Van den Broeck</a> (University of California, Los Angeles, USA).
The symposium will start at <strong>13:00</strong> in the <strong>Department of Computer Science</strong> (<a href="https://www.google.be/maps/place/Celestijnenlaan+200A,+3001+Leuven/@50.8641061,4.6766437,17z/data=!3m1!4b1!4m5!3m4!1s0x47c16110fdaa4483:0xa0e21d4a20cbf0db!8m2!3d50.8641061!4d4.6788324">Celestijnenlaan 200A, 3001 Heverlee</a>), room <strong>05.152 (Java)</strong>.
</p>

<p align="justify">
<!--If you plan to attend the defence and or the symposium, please confirm your attendance by filling out <a href="https://doodle.com/poll/aqig2gvpmzprb9at"><strong>this form</strong></a>. -->
If you plan to atten the symposium and/or the defence, please confirm your attenance by filling out <a href="https://doodle.com/poll/g87pf4cityvxxtpp"><strong>this form</strong></a>.
<strong>Please note that the reception after the PhD defence is invitation only.</strong>
</p>

<hr>


<div class="program">


	<h1><strong>Symposium on Deep learning for complex relational data</strong><h1>

	<p>
		<strong>Date &amp time:</strong> Tuesday, December 11, 2018 at 14:00 <br/>
		<strong>Address:</strong> Celestijnenlaan 200A, 3001 Heverlee<br/>
		<strong>Location:</strong> <i>05.152 (Java)</i>
	</p>

	<br/>




	<h2><strong>[13:00] Guy Van den Broeck: Probabilistic and Logistic Circuits: A New Synthesis of Logic and Machine Learning <a href="http://web.cs.ucla.edu/~guyvdb/talks/KULeuven18.pdf">(slides)</a></strong></h2>

	<p>
		<strong>Abstract:</strong>
		This talk will discuss three lines of recent work at the intersection of logical reasoning and statistical machine learning.
		First, I describe tractable logical circuits and how they can be used to enforce constraints on the output of deep neural networks.
		Second, such circuits can be generalized to statistical classifiers, called logistic circuits, that achieve better classification accuracy on MNIST than neural networks that are an order of magnitude larger.
		Finally, I discuss how probabilistic circuits perform state-of-the-art probabilistic inference in factor graphs as well as imperative probabilistic programs.
	</p>

	<div class="profile col defence-member right">
                
                        <img class="defence-member" src="/assets/img/defence/guy.jpg">
                
        </div>

	<p>
		<strong>Bio:</strong>
		Guy Van den Broeck is an Assistant Professor and Samueli Fellow at <a href="http://www.ucla.edu/">UCLA</a>, in the <a href="http://www.cs.ucla.edu/">Computer Science Department</a>, where he directs the <a href="http://web.cs.ucla.edu/~guyvdb/starai-lab">Statistical and Relational Artificial Intelligence (StarAI) lab</a>.
		His research interests are in Machine Learning (Statistical Relational Learning, Tractable Learning), Knowledge Representation and Reasoning (Graphical Models, Lifted Probabilistic Inference, Knowledge Compilation), Applications of Probabilistic Reasoning and Learning (Probabilistic Programming, Probabilistic Databases), and Artificial Intelligence in general.
	</p>


	<br/>



	<h2><strong>[14:00] Mathias Niepert: Neural Representation Learning for Graphs<a href="/assets/pdf/2018/Symposium_MathiasNiepert.pdf">(slides)</a></strong></h2>

	<p>
		<strong>Abstract:</strong>
		Graph-structured data is ubiquitous and occurs in numerous application domains.
		The talk will provide an overview of graph representation learning approaches such a graph convolutional networks.
		We show that these approaches can be understood from two different perspectives: as a special case of tensor factorizations and as instances of a class of algorithms that learn from local graph structures such as paths and neighborhoods.
		The talk will also discuss current work of our group including applications of graph neural networks.
	</p>

	<div class="profile col defence-member right">
                
                        <img class="defence-member" src="/assets/img/defence/mathias.png">
                
        </div>

	<p>
		<strong>Bio:</strong>
		Mathias Niepert is a chieft research scientist of the Systems and Machine Learning (SysML) group at <a href="https://uk.nec.com/en_GB/emea/about/neclab_eu">NEC Labs Heidelberg</a>.
		His research interests include representation learning for graph-structured data, unsupervised and semi-supervised learning, probabilistic graphical models, and statistical relational learning.
		He is co-founder of several open-source digital humanitites projects such as the <a href="https://www.inphoproject.org/">Indiana Philosophy Ontology Project</a> and the <a href="https://prodema-online.de/home/">Linked Humanities Project</a>.
		Before joining NEC Labs Heidelberg, he was a research at the University of Washington in Seattle and a member of the <a href="https://dws.informatik.uni-mannheim.de/en/home/">Data and Web Science Research Group</a> at the <a href="https://www.uni-mannheim.de/en/">University of Mannheim</a>.
	</p>


	<br/>

	<h2><strong>[15:00] Coffee break</strong></h2>

	<br/>



	<h2><strong>[15:30] Sebastian Riedel: Reading and Reasoning with Neural Program Interpreters <a href="/assets/pdf/2018/Symposium_SebastianRiedel.pdf">(slides)</a></strong></h2>


	<p>
	<strong>Abstract:</strong> We are getting better at teaching end-to-end neural models how to answer questions about content in natural language text. However, progress has been mostly restricted to extracting answers that are directly stated in the text. In this talk, I will present our work towards teaching machines not only to read but also to reason with what was read and to do this in an interpretable and controlled fashion. Our main hypothesis is that this can be achieved by the development of neural abstract machines that follow the blueprint of program interpreters for real-world programming languages. We test this idea using two languages: an imperative (Forth) and a declarative (Prolog/Datalog) one. In both cases, we implement differentiable interpreters that can be used for learning reasoning patterns. Crucially, because they are based on interpretable host languages, the interpreters also allow users to easily inject prior knowledge and inspect the learnt patterns. Moreover, on tasks such as math word problems and relational reasoning, our approach compares favourably to state-of-the-art methods.
	</p>

	<div class="profile col defence-member right">
    		
      			<img class="defence-member" src="/assets/img/defence/sebastian.jpg">
    		
 	</div>

	<p>
		<strong>Bio:</strong>
		Sebastian Riedel is a reader in Natural Language Processing and Machine Learning at the <a href="https://www.ucl.ac.uk/">University College London</a> (UCL), where he is leading the <a href="https://mr.cs.ucl.ac.uk/">Machine Reading lab</a>.
		He is also the head of research at <a href="https://bloomsbury.ai/">Bloomsbury AI</a> and an <a href="http://www.pgafamilyfoundation.org/programs/investigators-fellows/key-initiative/adi-artificial-intelligence-awards">Allen Distinguished Investigator</a>.
		He works in the intersection of Natural Language Processing and Machine Learning, and focuses on teaching machines how to read and reason.
		He was educated in Hamburg-Harburg (Dipl. Ing) and Edinburgh (MSc., PhD), and worked at the University of Massachusetts Amherst and Tokyo University before joining UCL.
	</p>

	<br/>

	<p>
		The symposium is kindly sponsored by the <a href="https://set.kuleuven.be/phd">Arenberg Doctoral School</a> through the <i>Meet the Jury</i> funding.
	</p>

	<hr width=50%/>

	<h2><strong>[17:00] Public PhD defence</strong></h2>
	<h1><strong>Learning Symbolic Latent Representations for Relational Data <a href="/assets/pdf/2018/Symposium_SebastijanDumancic.pdf">(slides)</a></strong></h1>

	<p>
		<strong>Date &amp time:</strong> Tuesday, December 11, 2018 at 17:00<br/>
		<strong>Address:</strong> Kasteel van Arenberg, Kasteelpark Arenberg 1, 3001 Heverlee<br/>
		<strong>Location:</strong> Auditorium (KAST 01.07)
	</p>


	<p>
		<strong>Supervisor:</strong> Hendrik Blockeel<br/>
		<strong>Examination Committee:</strong> Carlo Vandecasteele (chairman), Johan Suykens, Jesse Davis, David Poole, Sebastian Riedel, Mathias Niepert
	</p>

	<p>
		<strong>Abstract</strong><br/>
		The early 21<sup>st</sup> century has been largely shaped by the huge amounts of available data generated by the widespread adoption of information technology.
		This rapid growth of the stored data has created the need for automated tools capable of extracting useful bits from large amounts of data.
		In turn, such tools have changed our perspective on data from a mere record of an event to a carrier of useful information.
		Before insights can be drawn from the data, the data has to be first brought into a suitable form by means of <i>feature engineering</i> as it can rarely be processed in its <i>raw</i> form.
		This step is usually time- and labour-intensive, and often requires an extensive knowledge of the domain.
	</p>

	<p>
		In this thesis, we tackle the problem of <i>representation learning</i> -- how to automate the process of feature construction?
		We focus on feature construction with rich relational data expressed in form of networks, e.g., biological and traffic networks, as many real-life problems can be easily expressed in this format.
		To be able to express complex feature over networks, the proposed methods rely on the expressive data representation language of first-order logic.

	</p>

	<p>
		The first contribution of the thesis is a new versatile relational clustering framework that decouples various sources of relational similarity and combines them in a systematic manner.
		The second contribution is CUR<sup>2</sup>LED  -- a relational representation learning framework that exploits approximate symmetries in relational data as features.
		The third contribution are <i>Auto-encoding logic programs</i>  -- a relational generalisation of auto-encoders, one of the basic representation learning primitives.
		The fourth contribution is the experimental comparison of various relational representation learning methods that offers insights into the strengths and weaknesses of the existing approaches.
	</p>

	<br/>

	<h2><strong>[18:30] Reception</strong></h2>

	<hr>
</div>

  </article>

  

</div>

      </div>
    </div>

    <footer>

  <div class="wrapper">
    &copy; Copyright 2021 Sebastijan Dumančić.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
  </div>

</footer>


    <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


<!-- Load KaTeX -->
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js"></script>
<script src="/assets/js/katex.js"></script>




<!-- Include custom icon fonts -->
<link rel="stylesheet" href="/assets/css/fontawesome-all.min.css">
<link rel="stylesheet" href="/assets/css/academicons.min.css">

<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-99599995-2', 'auto');
ga('send', 'pageview');
</script>


  </body>

</html>
